										NATIONAL INSTITUTE OF TECHNOLOGY
 											    KURUKSHETRA

											   PRACTICAL FILE 
SUBJECT:- CSPE-64
Branch:-  COE
Roll no.:- 12112010
                                      Submitted to:- Dr.Vikram Singh                Submitted by:- Arjun Ramavath


											   ASSIGNMENT-1
* NIT KURUKSHETRA
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
links=['https://nitkkr.ac.in/?page_id=875','https://nitkkr.ac.in/?page_id=791','https://nitkkr.ac.in/?page_id=1953','https://nitkkr.ac.in/?page_id=1748','https://nitkkr.ac.in/?page_id=1026','https://nitkkr.ac.in/?page_id=1100','https://nitkkr.ac.in/?page_id=2028','https://nitkkr.ac.in/?page_id=952','https://nitkkr.ac.in/?page_id=1819']
with open('nitkkr.csv', 'w', encoding='utf8', newline='') as f:
        thewriter = writer(f)
        header = ['Name', 'Email', 'Phone', 'Area of interest']
        thewriter.writerow(header)
        for i in range(9):
            html_text = requests.get(links[i]).text
            soup = BeautifulSoup(html_text, 'lxml')
            faculty = soup.find_all('div', class_='col-md-12 pr_20')
        # not_needed='Publications'
            for teachers in faculty:
                name = teachers.find('h3').text.replace("\xa0", "")
                email = teachers.find(
                    'div', class_='left-sec').text.split(':')[3].split('\n')[0].replace("\xa0", "")
                phone = teachers.find(
                    'div', class_='left-sec').text.split(':')[4].split('\n')[0].replace("\xa0", "")
                aoi = teachers.find(
                    'div', class_='left-sec').text.split(':')[5].split('\n')[0].replace("\xa0", "")
                # print("Name:",name)
                # print("Email:",email)
                # print("Phone:",phone)
                # print("Area of interest:",aoi)
                info = [name, email, phone, aoi]
                thewriter.writerow(info)
                # print('\n')

* MNIT JAIPUR
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
link=['https://mnit.ac.in/dept_cse/people','https://mnit.ac.in/dept_arch/people','https://mnit.ac.in/dept_chemical/people','https://mnit.ac.in/dept_chemistry/people','https://mnit.ac.in/dept_civil/people','https://mnit.ac.in/dept_ee/people','https://mnit.ac.in/dept_ece/people']
with open('mnitjaipur.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Name', 'Email', 'Phone', 'Area of interest']
    thewriter.writerow(header)
    for i in range(7):
        html_text2 = requests.get(link[i]).text
        soup2 = BeautifulSoup(html_text2, 'lxml')
        faculty2 = soup2.find_all('div', class_='col-md-9 mt-3 profileDetails')
        # not_needed='Publications'
        
        for teachers in faculty2:
            name = teachers.find('h5', class_='m-0').text
            email = teachers.find('a').text
            phone = teachers.find_all('span', class_='d-inline-block mt-1')
            aoi = teachers.find_all('span', class_='d-inline-block mt-1')
                # print("Name:",name)
                # print("Email:",email)
            if (len(phone) > 3):
                phone = phone[3].text
                    # print("Phone:",phone)
            else:
                phone = 0
            aoi = aoi[1].text
                # print("Area of interest:",aoi)
                # print('\n')
                # print("Email:",email)
                # print("Phone:",phone)
                # print("Area of interest:",aoi)
            info = [name, email, phone, aoi]
            thewriter.writerow(info)
                # print('\n')

* NIT GOA
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
html_text4=requests.get('https://www.nitgoa.ac.in/EMPBiodata.aspx').text
soup4=BeautifulSoup(html_text4,'lxml')
faculty4=soup4.find_all('div',class_='col-md-4 col-sm-6 text-center')
#print(faculty4)
with open('nitgoa.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Name', 'Email', 'Phone','Research Area']
    thewriter.writerow(header)
    for teachers in faculty4:
        name=teachers.find('h2').text.replace('\n','')
        matter=teachers.find_all('p')
        email=matter[3].text.split(':')[1]
        phone=matter[4].text.split(':')[1]
        ResearchArea=matter[5].text.split(':')[1]
        print("Name:",name)
        print("Email:",matter[3].text.split(':')[1])
        print("Phone:",matter[4].text.split(':')[1])
        print("Research Area:",matter[5].text.split(':')[1])
        # print("Phone:",phone)
        info = [name, email, phone,ResearchArea]
        thewriter.writerow(info)


* NIT CALICUT
Source Code:
from urllib.request import urlopen
from bs4 import BeautifulSoup as soup
def surathkal(str):
    return str.strip().replace("\n", "").replace("\xa0", "")


def cal(str):
    return str.strip().replace("\n", "").replace("\xa0", "")


def nitc(URL):
    url = urlopen(URL)
    bsobj = soup(url.read(), "lxml")
    file = open("master-file.txt", "a+", encoding="utf-8")
    name = bsobj.select("[id~=mission_cap_arch]")[0].text
    file.write(name+"\n")
    profile = bsobj.select("[id~=welcomecontent_arch] tr")[2:]
    for p in profile:
        if 'E-mail' in p.text or 'Phone' in p.text:
            file.write(cal(p.text)+"\n")
    file.write("\n")
    file.close()


def NITC():
    url = "https://www.nitc.ac.in"
    site = urlopen(url+"/index.php/?url=department")
    obj = soup(site.read(), 'lxml')
    links = obj.select("#welcomecontent a[href]")
    file = open("master-file.txt", "a+", encoding="utf-8")
    file.write("\n\n----------------------------------------------\n")
    file.write(obj.title.text+"\n\n")
    file.close()
    for a in range(10):
        list = links[a].get('href')
        if '/index' in list:
            list = url+list.replace("/index/", "/people/")+"/0/5"
            site = urlopen(list)
            obj = soup(site.read(), 'lxml')
            for l in obj.select('[id~=welcomecontent_arch] a[href]')[1:]:
                lis = url+l.get('href')
                if 'user' in lis:
                    nitc(lis)
        print("âœ“ NIT Calicut - Working...")

if __name__ == "__main__":
    file = open("master-file.txt", "w+", encoding="utf-8")
    file.close()
    NITC()

* NIT SURAT
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
links=['https://www.svnit.ac.in/web/department/computer/faculty.php','https://www.svnit.ac.in/web/department/chemical/faculty.php','https://www.svnit.ac.in/web/department/civil/faculty.php','https://www.svnit.ac.in/web/department/Electrical/faculty.php','https://www.svnit.ac.in/web/department/Electronics/faculty.php','https://www.svnit.ac.in/web/department/Mechanical/faculty.php']
with open('nitsurat.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Name', 'Email', 'Phone','Research Area']
    thewriter.writerow(header)
    for i in range(6):
        html_text4=requests.get(links[i]).text
        soup4=BeautifulSoup(html_text4,'lxml')
        faculty4=soup4.find_all('div',class_='col-xs-12 col-sm-8 col-lg-10 remove_space')
        #print(faculty4)      
        for teachers in faculty4:
            name=teachers.find('h4',class_='author-name').text
            matter=teachers.find('div',class_='col-lg-4 col-xs-12 col-sm-12').text.replace('No.','').split()[1]
            email=teachers.find('div',class_='col-lg-8 col-xs-12 col-sm-12').text.replace('\n','').split()[2]
            if(teachers.find('p')!=None):
               aoi=teachers.find('p').text.replace('\n','').split(':')
            else:
                aoi='null'
            if(len(aoi)>=2):
                aoi=aoi[1]
            else:
                aoi='null'
            #email=email.replace('\xa0','')
            print("Name:",name)
            print("Email:",email)
            print("Mobile Number:",matter)
            print("AOI:",aoi)
            # print("Phone:",phone)
            info = [name, email, matter,aoi]
            thewriter.writerow(info)


* NIT DURGAPUR
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
links=['https://nitdgp.ac.in/department/computer-science-engineering/faculty-1','https://nitdgp.ac.in/department/biotechnology/faculty-2','https://nitdgp.ac.in/department/civil-engineering/faculty-3','https://nitdgp.ac.in/department/chemical-engineering/faculty-4','https://nitdgp.ac.in/department/electrical-engineering/faculty-7','https://nitdgp.ac.in/department/mechanical-engineering/faculty-11']
with open('nitdurgapur.csv', 'w', encoding='utf8', newline='') as f:
        thewriter = writer(f)
        header = ['Name', 'Email', 'Phone', 'Area of interest']
        thewriter.writerow(header)
        for i in range(6):
            html_text = requests.get(links[i]).text
            soup = BeautifulSoup(html_text, 'lxml')
            faculty = soup.find_all('div', class_='col-lg-2')
        # not_needed='Publications'
            for teachers in faculty:
                name = teachers.find('h4',class_='card-title').text
                matter=teachers.find_all('p')
                aoi=matter[0].text.replace('\n','')
                #aoi=aoi.replace('\r','')
                email=matter[1].text.replace('\t','').split(' ')
                if(len(email)>=2):
                    email1=email[1]
                else:
                    email1=email[0]
                if(len(email)>=4):
                    phone=email[3]
                else:
                    if(len(email)>=3):
                       phone=email[2]
                    else:
                       if(len(email)>=2):
                           phone=email[1]
                       else:
                           phone=email[0]
                print("Name:",name)
                print("Area of interest:",aoi)
                print("Email:",email1)
                print("Phone:",phone)
                
                info = [name, email1, phone, aoi]
                thewriter.writerow(info)
                # print('\n')

* NIT DELHI
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
links=['https://nitdelhi.ac.in/?page_id=11977','https://nitdelhi.ac.in/?page_id=11979','https://nitdelhi.ac.in/?page_id=11985','https://nitdelhi.ac.in/?page_id=11981','https://nitdelhi.ac.in/?page_id=11993']
with open('nitdelhi.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Name', 'Email', 'Phone','Research Area']
    thewriter.writerow(header)
    for i in range(5):
        html_text4=requests.get(links[i]).text
        soup4=BeautifulSoup(html_text4,'lxml')
        faculty4=soup4.find_all('div',class_='computersci')
        #print(faculty4)
        data=soup4.find_all('td',class_='scienceimage')       
        for teachers in faculty4:
            phone=data[0].text
            matter=teachers.text.split(':')
            name=matter[1].split("Email")[0]
            email=matter[2].split('Designation')[0]
            x=len(matter)
            if(x>5):
               aoi=matter[5]
            else:
                aoi=matter[4]
            print("Name:",name)
            print("Email:",email)
            print("Area of Interest:",aoi)
            print("Phone:",phone)
            # print("Phone:",phone)
            info = [name, email, phone,aoi]
            thewriter.writerow(info)


* NIT MEGHALAYA
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
link=['https://www.nitm.ac.in/department/computer-science-engineering/faculty-1','https://www.nitm.ac.in/department/civil-engineering/faculty-6','https://www.nitm.ac.in/department/electrical-engineering-1/faculty-2','https://www.nitm.ac.in/department/electronics-communication-engineering-2/faculty','https://www.nitm.ac.in/department/mechanical-engineering-1/faculty-7']
with open('nitmeghalaya.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Name', 'Email', 'Phone', 'Area of interest']
    thewriter.writerow(header)
    for i in range(5):
        html_text2 = requests.get(link[i]).text
        soup2 = BeautifulSoup(html_text2, 'lxml')
        faculty2 = soup2.find_all('div', class_='col-sm-10')
        # not_needed='Publications'
        for teachers in faculty2:
            name=teachers.find('h3').text.split('Ph')[0]
            aoi=teachers.find('div',class_='researchint').text.replace('\n','')
            aoi=aoi.replace('\t','').split('Research Interest')[1]
            matter=teachers.find_all('a')
            email=matter[0].text
            if(len(matter)>=2):
               phone=matter[1].text
            print("Name:",name)
            print("AOI:",aoi)
            print("Email:",email)
            if(phone!='Read more'):
               print("Phone:",phone)
            else:
                phone=-1
            info = [name, email, phone, aoi]
            thewriter.writerow(info)
                # print('\n')

* NIT SIKKIM
Source Code:
import requests
from bs4 import BeautifulSoup


def scrape(url):
    soup = BeautifulSoup(requests.get(url).text, "html.parser")
    rows = soup.find_all(attrs={"class": "container-fluid"})[0].div

    profs = rows.find_all(attrs={"class": "col-md-4"})

    for prof in profs:
        for data in prof.div.div.strings:
            if (data != "More"):
                print(data)
        print("\n----------------------------------------\n")


def parse(url):
    names = {"cse": "Computer Engineering Department", "ece": "Electronics and Communication Department",
             "eee": "EEE Department Details", "ce": "Civil Engineering Department Details"}

    start_index = 8
    end_index = url.find(".")
    dept = url[start_index: end_index]
    return names[dept]


urls = ["https://cse.nitsikkim.ac.in/people.php", "https://ece.nitsikkim.ac.in/people.php",
        "https://eee.nitsikkim.ac.in/people.php", "https://ce.nitsikkim.ac.in/people.php"]

for url in urls:
    print("********************************\n")
    print("Printing details for", parse(url),"->->->->\n")
    
    scrape(url)

	
* NIT MIZORAM
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
links=['https://www.nitmz.ac.in/EMPBiodata.aspx']
with open('nitmizoram.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Name', 'Email','Research Area']
    thewriter.writerow(header)
    for i in range(1):
        html_text4=requests.get(links[i]).text
        soup4=BeautifulSoup(html_text4,'lxml')
        faculty4=soup4.find_all('table',attrs={'cellpadding':'0','cellspacing':'0','width':'100%','style':'line-height: 25px'})
        #print(faculty4)      
        for teachers in faculty4:
            matter=teachers.find_all('td',class_='link-smallProfile')
            name=matter[0].text.replace('\n','')
            email=matter[2].text.split()[3]
            aoi=teachers.find_all('tr')
            aoi1=aoi[4].text.replace('\r','')
            aoi1=aoi1.replace('\n','').split(':')[1]
            print("Name:",name)
            print("Email:",email)
            print("Area of Interest:",aoi1)
            info = [name, email,aoi1]
            thewriter.writerow(info)


* NIT NAGALAND
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
links=['https://www.nitnagaland.ac.in/index.php/cse-people/cse-faculty']
with open('nitnagaland.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Name', 'Email','Research Area']
    thewriter.writerow(header)
    for i in range(1):
        html_text4=requests.get(links[i]).text
        soup4=BeautifulSoup(html_text4,'lxml')
        faculty4=soup4.find_all('div',class_='fp-testimonials')      
        for teachers in faculty4:
            name=teachers.find('b').text
            email=teachers.find('div').text.split('\n')[3]
            matter=teachers.find('div').text.split('\n')[4]
            aoi=matter.split(":")[1]
            print("Name:",name)
            print("Email:",email)
            print("Aoi:",aoi)
            info = [name, email,aoi]
            thewriter.writerow(info)


* NIT UTTARAKHAND
Source Code:
from bs4 import BeautifulSoup
import requests
from csv import writer
links=['https://nituk.ac.in/computer-science-engineering/peoples','https://nituk.ac.in/civil-engineering/peoples','https://nituk.ac.in/electrical-engineering/peoples','https://nituk.ac.in/electronics-engineering/peoples','https://nituk.ac.in/mechanical-engineering/peoples']
with open('nituttr.csv', 'w', encoding='utf8', newline='') as f:
    thewriter = writer(f)
    header = ['Name', 'Email', 'Phone','Research Area']
    thewriter.writerow(header)
    for i in range(5):
        html_text4=requests.get(links[i]).text
        soup4=BeautifulSoup(html_text4,'lxml')
        faculty4=soup4.find_all('td',attrs={'width':'400'})
        #print(faculty4)      
        for teachers in faculty4:
            name=teachers.find('a').text.replace('\n','')
            matter=teachers.find('span').text.split(':')
            if(len(matter)>=5):
               email=matter[4]
            else:
                email='null'
            if(len(matter)>=3):
               phone=matter[2]
            else:
                phone='null'
            #phone=matter[2]
            if(len(matter)>=6):
               aoi=matter[5]
            print("Name:",name)
            print("Email:",email)
            print("Area of Interest:",aoi)
            print("Phone:",phone)
            # print("Phone:",phone)
            info = [name, email, phone,aoi]
            thewriter.writerow(info)


* NIT SRINAGAR
Source Code:
import requests
from bs4 import BeautifulSoup

url = "https://www.nitsri.ac.in/Pages/DepartmentList.aspx"

r = requests.get(url)

soup = BeautifulSoup(r.content,'html.parser')

dept = soup.find_all('h3',class_="gdlr-core-event-item-title")
for d in dept:
    print(d.text)
    depturl = d.find('a').get('href')
    faculurl = "https://www.nitsri.ac.in/Pages/FacultyList.aspx?nDeptID="+depturl.split("DeptID=")[1]
    faculreq= requests.get(faculurl)
    faculsoup = BeautifulSoup(faculreq.content,'html.parser')
    alldet = faculsoup.find_all('div',class_="gdlr-core-personnel-list-content-wrap")
    for de in alldet:
        name = de.find('h3')
        if(name!=None):
            print("Name : ",name.text.strip())
        desgn = de.find('div',class_="gdlr-core-info-font")
        if(desgn!=None):
            print("Designation : ",desgn.text.strip())
        mail = de.find('div',class_="kingster-type-mail")
        phone = de.find('div',class_="kingster-type-phone")
        if(mail!=None):
            print("Email : ",mail.text.strip())
        if(phone!=None):
            print("Phone : ",phone.text.strip())
        area = de.find('div',class_="gdlr-core-personnel-list-content")
        if(area!=None):
            print("Area of Interests :",area.text.strip())
        print('\n')
    

* NIT BHOPAL
Source Code:
import requests
from bs4 import BeautifulSoup
url = "http://www.manit.ac.in/"

r = requests.get(url)

htmlcontent = r.content

soup = BeautifulSoup(htmlcontent,'html.parser')

allli = soup.find('li',class_='menu-344')
alllink = allli.find('ul').find_all('a')
for ln in alllink:
    facullink = "http://www.manit.ac.in"+ln.get('href')
    faculreq = requests.get(facullink)
    faculsoup = BeautifulSoup(faculreq.content,'html.parser')
    peoples = faculsoup.find('div',class_="peoplearea")
    if(peoples!=None):
        names = peoples.text
        names = names.replace("[at]","@")
        names = names.replace("[dot]",".")
        print(names)

* MNNIT
Source Code:
import requests
from bs4 import BeautifulSoup
url = "http://www.mnnit.ac.in/"

r = requests.get(url)

htmlcontent = r.content

soup = BeautifulSoup(htmlcontent,'html.parser')

navitems = soup.find('li',class_='item-669')
print(navitems.find('a').text)
eng = navitems.find('li',class_='item-695')
print(eng.find('a').text)
departments = eng.find_all('li',class_='parent')
for dept in departments:
    print(dept.find('a').text)
    allmenu = dept.find_all('a')
    for opt in allmenu:
        facul = opt.text
        if(facul=='Faculty Profile'):
            facultyurl = opt.get('href')
            faculurl = "http://www.mnnit.ac.in"+facultyurl
            facultyreq = requests.get(faculurl)
            facultycontent = facultyreq.content
            faculsoup = BeautifulSoup(facultycontent,'html.parser')
            
            teachtable = faculsoup.find('table')
            teachrow = teachtable.find_all('tr')
            for teachers in teachrow:
                print(teachers.text.strip())
                print('')


* NIT TRICHY
Source Code:
import requests
from bs4 import BeautifulSoup
url = "https://www.nitt.edu/"

r = requests.get(url)

htmlcontent = r.content

soup = BeautifulSoup(htmlcontent,'html.parser')

dept = soup.find('li',class_='menu-item-93')
link = dept.find('a').get('href')

depreq = requests.get(link)
depsoup = BeautifulSoup(depreq.content,'html.parser')
depart = depsoup.find_all('div',class_='facitem')
for ln in depart:
    urli ="https://www.nitt.edu/home/academics/departments/" + ln.find('a').get('href')
    faculurl = urli+"faculty"
    faculreq = requests.get(faculurl)
    faculsoup = BeautifulSoup(faculreq.content,'html.parser')
    teachers = faculsoup.find_all('div',class_='facitem')
    for tech in teachers:
        name = tech.find('a')
        if(name!=None):
            print("Name : ",name.text.strip())
        interest = tech.find('p')
        if(interest!=None):
            print("Research Interests",interest.text.strip())
    
* NIT SURATHKAL
Source Code:
from urllib.request import urlopen
from bs4 import BeautifulSoup as soup
def surathkal(str):
    return str.strip().replace("\n", "").replace("\xa0", "")


def nitk(URL):
    url = urlopen(URL)
    bsobj = soup(url.read(), "lxml")
    file = open("master-file.txt", "a+", encoding="utf-8")
    file.write(bsobj.title.text+"\n")
    file.write(bsobj.select('[class~=node-content] > div')[0].text+"\n")
    profile = bsobj.select('fieldset ')
    for a in profile:
        if 'Contact' in a.text:
            for l in a.select('[class~=section]'):
                file.write(l.text.strip()+"\n")
        elif 'Areas of Interest' in a.text:
            file.write(surathkal(a.legend.text) +
                       " : "+surathkal(a.div.text)+"\n")
    file.write("\n")
    file.close()

def NITK():
    url = "https://www.nitk.ac.in/departments-and-centers"
    site = urlopen(url)
    obj = soup(site.read(), 'lxml')
    links = obj.select("[class~=kingster-page-wrapper] h3 a[href]")
    file = open("master-file.txt", "a+", encoding='UTF-8')
    file.write("\n\n----------------------------------------------\n")
    file.write("National Institute of Technology,Surathkal,Karantaka \n\n")
    file.close()
    for a in links:
        list = a.get('href')
        site = urlopen(list)
        obj = soup(site.read(), 'lxml')
        for l in obj.select('a[href]'):
            if l.text == "People" or l.text == "Faculty":
                site = urlopen(list+l.get('href')[1:])
                obj = soup(site.read(), 'lxml')
                for p in obj.select('[id~=main-content] span a[href]'):
                    prof = p.get('href')
                    if 'professor' in prof:
                        prof = list+prof[prof.find('/professor')+1:]
                    elif 'faculty' in prof:
                        prof = list+prof[prof.find('/faculty')+1:]
                    else:
                        continue
                    nitk(prof)
                break
        print("âœ“ NIT SURATHKAL Working...")
if __name__ == "__main__":
    file = open("master-file.txt", "w+", encoding="utf-8")
    file.close()
    NITK()


* NIT Puducherry
doc = docx.Document()

options = Options()
options.add_argument("--headless")
driver = webdriver.Firefox(options=options)

doc.add_paragraph("Full Name \n Designation \n Email ID \n Contact Number \n Research area")

url_list = ["https://nitpy.ac.in/academics/departments/civil/faculty",
            "https://nitpy.ac.in/academics/departments/cse/faculty",
            "https://nitpy.ac.in/academics/departments/ece/faculty",
            "https://nitpy.ac.in/academics/departments/eee/faculty",
            "https://nitpy.ac.in/academics/departments/mech/faculty"
            ]

for page in url_list:
    driver.get(page)
    driver.refresh()
    soup = BeautifulSoup(driver.page_source, "html.parser")
    s = soup.find_all("app-department-faculty-view")
    for faculty in s:
        facultyData = faculty.find_all("p")

        # Faculty Name
        fac_name = facultyData[0].text.split(":")[1].strip()

        # Designation
        fac_designation = facultyData[1].text.split(":")[1].strip()

        # E-Mail
        fac_email = facultyData[2].text.split(":")[1].strip()

        # Phone Number
        fac_phone = facultyData[3].text.split(":")[1].strip()
	  fac_research = "-"

        if len(facultyData) >= 5:
            try:
                fac_research = facultyData[4].text.split(":")[1].strip()
            except:
                fac_research = "-"
            finally:
                pass
        doc.add_paragraph("\n==============================================================\n" +
                          fac_name + " \n" + fac_designation + " \n " + fac_email + " \n " +
                          fac_phone + " \n " + fac_research)

doc.save('output.docx')
print("Done NIT Puducherry")

* NIT Rourkela
from urllib.request import urlopen
from bs4 import BeautifulSoup as soup
def rkl(str):
    return str.strip().replace("\n", "").replace("\xa0", "")


def nitrkl(URL):
    url = urlopen(URL)
    bsobj = soup(url.read(), "lxml")
    profile = bsobj.select("[class~=blog-content-faculty]")
    file = open("master-file.txt", "a+", encoding='UTF-8')
    for p in profile:
        if 'SANSKRIT' in p.text:
            continue
        for line in (p.text).split("\n"):
            if "View Profile" in line:
                continue
            if len(rkl(line)) > 1:
                file.write(rkl(line)+"\n")
        file.write("\n")
    file.write("\n----------------------------------------------\n")
    file.close()


def NITRKL():
    url = "https://website.nitrkl.ac.in/"
    site = urlopen(url)
    obj = soup(site.read(), 'lxml')
    links = obj.select("[id~=submenu-department] li a[href]")
    file = open("master-file.txt", "a+", encoding='UTF-8')
    file.write("\n\n----------------------------------------------\n")
    file.write(obj.title.text+"\n\n")
    file.close()

    for a in links:
        list = a.get('href')
        site = urlopen(list)
        obj = soup(site.read(), 'lxml')
        for l in obj.select('a[href]'):
            if l.text == "Faculty":
                list = url+l.get('href')[3:]
                nitrkl(list)
        print("âœ“ NIT ROURKELA Working...")
if __name__ == "__main__":
    file = open("master-file.txt", "w+", encoding="utf-8")
    file.close()
    NITRKL()


* NIT Warangal
from urllib.request import urlopen
from bs4 import BeautifulSoup as soup
def warangal(str):
    return str.strip().replace("\n", "").replace("\xa0", "")


def nitw(URL):
    url = urlopen(URL)
    bsobj = soup(url.read(), "lxml")
    name = bsobj.select("[class~=hd]")
    profile = bsobj.select("[class~=rightm]")
    file = open("master-file.txt", "a+", encoding='UTF-8')
    for profile in profile:
        for line in (profile.text).split("\n"):
            if len(warangal(line)) > 1:
                file.write(warangal(line)+"\n")
        file.write("\n")
    file.write("----------------------------------------------\n")
    file.close()


def NITW():
    url = "https://wsdc.nitw.ac.in"
    site = urlopen(url+"/facultynew/dept/faculty_profiles/bt")
    obj = soup(site.read(), 'lxml')
    links = obj.select("[class~=branch-column] [class~=list-group] a[href]")
    file = open("master-file.txt", "a+", encoding='UTF-8')
    file.write("\n\n----------------------------------------------\n")
    file.write(obj.title.text+"\n\n")
    file.close()
    for a in links:
        if a.text != "All Faculty":
            list = url+a.get('href')
            nitw(list)
            print("âœ“ NIT WARANGAL Working...")
if __name__ == "__main__":
    file = open("master-file.txt", "w+", encoding="utf-8")
    file.close()
    NITW()

* VNIT Nagpur
import requests
from bs4 import BeautifulSoup
for i in element1:
    print(i)
    x = requests.get(i)
    htmlContent = x.content
    soup = BeautifulSoup(htmlContent, 'html.parser')
    y = soup.find_all(class_="peoplearea")
    file = open("output.txt", "a", encoding='utf-8')
    for j in y:
        for a in j.text.split("\n"):
            if (len(a) > 5):
                file.write(a+"\n")
        file.write("\n")
element1.clear()
element1 = []
element1.append("https://vnit.ac.in/cse/index.php/faculty/")
element1.append("https://vnit.ac.in/eee/index.php/faculty/")
element1.append("https://vnit.ac.in/mech/index.php/faculty/")
element1.append("https://vnit.ac.in/meta/index.php/faculty/")
element1.append("https://vnit.ac.in/ece/index.php/faculty/")
element1.append("https://vnit.ac.in/civil/index.php/faculty/")
element1.append("https://vnit.ac.in/chemical/index.php/faculty/")

* NIT Raipur
import requests
from bs4 import BeautifulSoup
for i in element1:
    print(i)
    x = requests.get(i)
    htmlContent = x.content
    soup = BeautifulSoup(htmlContent, 'html.parser')
    y = soup.find_all(class_="card-body")
    file = open("output.txt", "a", encoding='utf-8')
    for j in y:
        for a in j.text.split("\n"):
            if (len(a) > 5):
                file.write(a+"\n")
        file.write("\n")
element1.clear()

element1 = []
element1.append("http://www.nitrr.ac.in/aboutbiomed.php")
element1.append("http://www.nitrr.ac.in/aboutchemical.php")
element1.append("http://www.nitrr.ac.in/aboutcivil.php")
element1.append("http://www.nitrr.ac.in/aboutcse.php")
element1.append("http://www.nitrr.ac.in/aboutelectrical.php")
element1.append("http://www.nitrr.ac.in/aboutelectronics.php")
element1.append("http://www.nitrr.ac.in/aboutmechanical.php")
element1.append("http://www.nitrr.ac.in/aboutit.php")